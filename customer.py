# -*- coding: utf-8 -*-
"""Customer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YPbzgR2JJiYvPXytltSyXg7zOjA2575A
"""

import pandas as pd
import numpy as np
import datetime as dt

df = pd.read_csv('/content/online_mall_datset.csv')

df.head()

df.tail()

df.shape

df.isna().sum()

df.info()

df.describe()

df['invoice_date'] = pd.to_datetime(df['invoice_date'],infer_datetime_format=True,format='mixed',utc=True, errors='ignore')

df.info()

df_recency = df.groupby(by='customer_id',
                        as_index=False)['invoice_date'].max()
df_recency.columns = ['customer_id', 'invoice_date']
recent_date = df_recency['invoice_date'].max()
df_recency['Recency'] = df_recency['invoice_date'].apply(
    lambda x: (recent_date - x).days)
df_recency.head()

frequency_df = df.drop_duplicates().groupby(
	by=['customer_id'], as_index=False)['invoice_date'].count()
frequency_df.columns = ['customer_id', 'Frequency']
frequency_df.head()

monetary_df = df.groupby('customer_id')['price'].sum().reset_index()
monetary_scores = pd.qcut(monetary_df['price'], q=4, labels=range(1, 5))
monetary_df.columns = ['customer_id', 'Monetary']
monetary_df.head()

rf_df = df_recency.merge(frequency_df, on='customer_id')
rfm_df = rf_df.merge(monetary_df, on='customer_id').drop(
	columns='invoice_date')
rfm_df.head()

rfm_df['R_rank'] = rfm_df['Recency'].rank(ascending=False)
rfm_df['F_rank'] = rfm_df['Frequency'].rank(ascending=True)
rfm_df['M_rank'] = rfm_df['Monetary'].rank(ascending=True)

# normalizing the rank of the customers
rfm_df['R_rank_norm'] = (rfm_df['R_rank']/rfm_df['R_rank'].max())*100
rfm_df['F_rank_norm'] = (rfm_df['F_rank']/rfm_df['F_rank'].max())*100
rfm_df['M_rank_norm'] = (rfm_df['F_rank']/rfm_df['M_rank'].max())*100

rfm_df.drop(columns=['R_rank', 'F_rank', 'M_rank'], inplace=True)

rfm_df.head()

rfm_df['RFM_Score'] = 0.15*rfm_df['R_rank_norm']+0.28 * \
	rfm_df['F_rank_norm']+0.57*rfm_df['M_rank_norm']
rfm_df['RFM_Score'] *= 0.05
rfm_df = rfm_df.round(9)
rfm_df[['customer_id', 'RFM_Score']].head(7)

from sklearn.cluster import MiniBatchKMeans
from sklearn.preprocessing import StandardScaler
batch_size = 170

scaler = StandardScaler()
rfm_scaled = scaler.fit_transform(rfm_df)

kmeans = MiniBatchKMeans(n_clusters = 3,random_state=42, batch_size=170)
kmeans.fit(rfm_scaled)
cluster_labels = kmeans.predict(rfm_scaled)

kmeans.fit(rfm_scaled)

rfm_df['Cluster'] = cluster_labels

print(rfm_df['Cluster'].value_counts())

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

plt.scatter(rfm_df['Frequency'], rfm_df['Monetary'], c=rfm_df['Cluster'])
plt.xlabel('Frequency')
plt.ylabel('Monetary')
plt.show()

from sklearn.metrics import silhouette_score, davies_bouldin_score

silhouette = silhouette_score(rfm_scaled, cluster_labels)
print(f"Silhouette score: {silhouette}")

davies_bouldin = davies_bouldin_score(rfm_scaled, cluster_labels)
print(f"Davies-Bouldin index: {davies_bouldin}")

cluster_counts = rfm_df['Cluster'].value_counts().sort_index()
plt.bar(cluster_counts.index, cluster_counts.values)
plt.xlabel('Cluster')
plt.ylabel('Number of Customers')
plt.title('Customer Market Segmentation')
plt.show()